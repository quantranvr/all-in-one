{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "gBJy4xlzM02q",
        "FWNMYmj7Nasr"
      ],
      "authorship_tag": "ABX9TyP+N9e336qMFDLzbpJNGhdo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/quantranvr/all-in-one/blob/main/QA_with_RAG_series_part_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Intro"
      ],
      "metadata": {
        "id": "-0eAnjsTMXX4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tutorial @ https://python.langchain.com/docs/use_cases/question_answering/quickstart"
      ],
      "metadata": {
        "id": "0qx5LLs6M4cF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook contains 2 core parts:\n",
        "1. **Reproduce** [tutorial](https://python.langchain.com/docs/use_cases/question_answering/quickstart)'s example(s)\n",
        "2. **Apply** knowledge learned to solve a new (but similar) problem\n"
      ],
      "metadata": {
        "id": "mKUcrwZFMZtI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installation"
      ],
      "metadata": {
        "id": "gBJy4xlzM02q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXncCfN9LC5N",
        "outputId": "6f13b0bb-576a-4a72-e812-cd63fb0f8380"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m802.4/802.4 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m509.0/509.0 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m228.7/228.7 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.4/223.4 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.5/60.5 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.7/40.7 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.9/57.9 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.6/105.6 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m698.9/698.9 kB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m74.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m69.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade --quiet langchain langchain-community langchainhub langchain-openai chromadb bs4"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# API KEYS"
      ],
      "metadata": {
        "id": "FWNMYmj7Nasr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "openai_api_key = \"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\"\n",
        "\n",
        "# 2024.01.22\n",
        "# Thank you for signing up! LangSmith is still in closed beta and we're slowly\n",
        "# rolling access to more users. You are on a waitlist and we will get back to\n",
        "# you when we roll out more invites.\n",
        "langsmith_api_key = \"\""
      ],
      "metadata": {
        "id": "ZwtolFMrNYqs"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1: **Reproduce** [tutorial](https://python.langchain.com/docs/use_cases/question_answering/quickstart)'s example"
      ],
      "metadata": {
        "id": "jl8xl81xOW77"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`In this guide we’ll build a QA app over the LLM Powered Autonomous Agents blog post by Lilian Weng, which allows us to ask questions about the contents of the post.` ([Reference](https://python.langchain.com/docs/use_cases/question_answering/quickstart#preview))"
      ],
      "metadata": {
        "id": "2q8t2aHPPXv4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up environment variable `OPENAI_API_KEY`"
      ],
      "metadata": {
        "id": "Vg6RTGmbQaUq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai_api_key"
      ],
      "metadata": {
        "id": "1Rzsc-TrOg_o"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import"
      ],
      "metadata": {
        "id": "LpIDQlxfQi8f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for loading the blog post content\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "# for parsing HTML to text\n",
        "import bs4\n",
        "# for recursively splitting the document using common separators\n",
        "# until each chunk is the appropriate size\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "# for pulling prompt from langchain hub\n",
        "from langchain import hub\n",
        "# for vector store\n",
        "from langchain_community.vectorstores import Chroma\n",
        "# for parsing output\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "# for ?\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "# for setting up llm and embeddings\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings"
      ],
      "metadata": {
        "id": "v2T0v1CeOvwb"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load, chunk and index the contents of the [blog](https://lilianweng.github.io/posts/2023-06-23-agent/)"
      ],
      "metadata": {
        "id": "Z0WFQbBXQlGm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notes:\n",
        "1. In RecursiveCharacterTextSplitter, `add_start_index` is set to `True` so that the character index at which each split Document starts within the initial Document is preserved as metadata attribute “start_index”\n",
        "2. `TextSplitter` is a subclass of `DocumentTransformers` - an object that perfomrs a transformation on a list of documents\n",
        "3. *When we want to search over our splits, we take a text search query, embed it, and perform some sort of “similarity” search to identify the stored splits with the most similar embeddings to our query embedding. The simplest similarity measure is cosine similarity — we measure the cosine of the angle between each pair of embeddings (which are high dimensional vectors)*\n",
        "4. **Embedding** is wrapper around a text embedding model and used for converting text to embeddings\n",
        "5. **VectorStore** is wrapper around a vectordatabase and used for storing and querying embeddings"
      ],
      "metadata": {
        "id": "etTzJfPyVX_2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Going **deeper** at:\n",
        "1. [Document loaders](https://python.langchain.com/docs/integrations/document_loaders/) to choose from 160+ integrations\n",
        "2. [Document transformers](https://python.langchain.com/docs/integrations/document_transformers/) to select the appropriate integration\n",
        "3. [Embeddings](https://python.langchain.com/docs/integrations/text_embedding/) to select from 30+ integrations\n",
        "4. [VectorSctore](https://python.langchain.com/docs/integrations/vectorstores/) to select from 40+ integrations"
      ],
      "metadata": {
        "id": "cXfcdSpBT5UQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup document loader\n",
        "bs4_strainer = bs4.SoupStrainer(class_ = (\"post-content\", \"post-title\", \"post-header\"))\n",
        "loader = WebBaseLoader(\n",
        "    web_paths = (\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
        "    bs_kwargs = {\"parse_only\": bs4_strainer}\n",
        ")\n",
        "\n",
        "# Load the blog post content\n",
        "docs = loader.load()\n",
        "\n",
        "# Setup text splitter\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 1000,\n",
        "    chunk_overlap = 200,\n",
        "    add_start_index = True,\n",
        ")\n",
        "\n",
        "# Split the docs\n",
        "splits = text_splitter.split_documents(docs)\n",
        "\n",
        "# Embed the contents of each document split and\n",
        "# insert these embeddings into a vector database (or vector store)\n",
        "vectorstore = Chroma.from_documents(\n",
        "    documents = splits,\n",
        "    embedding = OpenAIEmbeddings()\n",
        ")"
      ],
      "metadata": {
        "id": "GL3TS6TIPVoz"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Retrieve and generate using the relevant snippets of the blog"
      ],
      "metadata": {
        "id": "1Xtaa-lLQsnT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notes:\n",
        "1. *We’ll use the [LCEL Runnable](https://python.langchain.com/docs/expression_language/) protocol to define the chain, allowing us to - pipe together components and functions in a transparent way*\n",
        "2."
      ],
      "metadata": {
        "id": "0YlTAuNQbFch"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Go **deeper** at:\n",
        "1. [Chat models](https://python.langchain.com/docs/integrations/chat/) to choose from 25+ integrations\n",
        "2. [LLM](https://python.langchain.com/docs/integrations/llms) to choose from 75+ integrations\n",
        "3. [Customized prompt](https://python.langchain.com/docs/integrations/llms) to learn more about customizing prompt"
      ],
      "metadata": {
        "id": "zIUmSQuKbGa1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn vector store into a retriever\n",
        "retriever = vectorstore.as_retriever()\n",
        "\n",
        "# Use a prompt for RAG that is checked into the LangChain prompt hub\n",
        "# https://smith.langchain.com/hub/rlm/rag-prompt?organizationId=1648f50c-3d41-5454-a345-8a3645232d42\n",
        "prompt = hub.pull(\"rlm/rag-prompt\")\n",
        "\n",
        "# Setup LLM\n",
        "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
        "\n",
        "# format retrieved info\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "# Pipe together components and functions\n",
        "rag_chain = (\n",
        "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")"
      ],
      "metadata": {
        "id": "MZ5kd64OQXzu"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# See what a prompt for RAG looks like\n",
        "example_messages = prompt.invoke(\n",
        "    {\"context\": \"filler context\", \"question\": \"filler question\"}\n",
        ").to_messages()\n",
        "print(f\"RAG Prompt example:\\n\\\"\\\"\\\"\\n{example_messages[0].content}\\n\\\"\\\"\\\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hL7LwIoFZ6Cn",
        "outputId": "565b7c47-905a-4464-be84-9e25c23333e7"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RAG Prompt example:\n",
            "\"\"\"\n",
            "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
            "Question: filler question \n",
            "Context: filler context \n",
            "Answer:\n",
            "\"\"\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Invoke the chain to answer user question\n",
        "rag_chain.invoke(\"What is Task Decomposition?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "2fy5MCX3SS57",
        "outputId": "b6ee71a5-674d-4269-a824-ff4d2ce86a9f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Task decomposition is a technique used to break down complex tasks into smaller and simpler steps. It can be done through prompting techniques like Chain of Thought or Tree of Thoughts, which guide the model to think step by step and explore multiple reasoning possibilities. Task decomposition can also involve task-specific instructions or human inputs.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cleanup\n",
        "vectorstore.delete_collection()"
      ],
      "metadata": {
        "id": "2qySxqP2SXuh"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2: **Apply** knowledge learned to similar problem"
      ],
      "metadata": {
        "id": "gb7jwDzDc0Ry"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem:\n",
        "\n",
        "A LangChain learner wants to understand certain concepts of LangChain Expression Language (LCEL).\n",
        "\n",
        "Retrieve information from this [docs](https://python.langchain.com/docs/expression_language/) to answer his questions"
      ],
      "metadata": {
        "id": "Iz0wsl2vc6JJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for loading the blog post content\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "# for parsing HTML to text\n",
        "import bs4\n",
        "# for recursively splitting the document using common separators\n",
        "# until each chunk is the appropriate size\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "# for pulling prompt from langchain hub\n",
        "from langchain import hub\n",
        "# for vector store\n",
        "from langchain_community.vectorstores import Chroma\n",
        "# for parsing output\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "# for ?\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "# for setting up llm and embeddings\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings"
      ],
      "metadata": {
        "id": "ZvSjN0bYjH8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load document\n",
        "bs4_strainer = bs4.SoupStrainer(class_=\"docMainContainer_gTbr\")\n",
        "loader = WebBaseLoader(\n",
        "    web_paths = (\"https://python.langchain.com/docs/expression_language/\",),\n",
        "    bs_kwargs = {\"parse_only\": bs4_strainer}\n",
        ")\n",
        "\n",
        "docs = loader.load()"
      ],
      "metadata": {
        "id": "zAYUjF-cczm0"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Document length = {len(docs[0].page_content)} characters\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAWvUWW1e2K3",
        "outputId": "0a8bce7d-18f3-4028-cca2-1e78b8892f30"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document length = 2743 characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# split document into chunks of text\n",
        "splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 800,\n",
        "    chunk_overlap = 100,\n",
        "    add_start_index = True\n",
        ")\n",
        "\n",
        "splits = splitter.split_documents(docs)"
      ],
      "metadata": {
        "id": "4gc6JNxzeSo8"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# store chunk of texts into vector store\n",
        "vectorstore = Chroma.from_documents(\n",
        "    documents = splits,\n",
        "    embedding = OpenAIEmbeddings(),\n",
        ")"
      ],
      "metadata": {
        "id": "rkOhJnfSetTc"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setup retriever\n",
        "retriever = vectorstore.as_retriever()\n",
        "\n",
        "# setup prompt\n",
        "prompt = hub.pull(\"rlm/rag-prompt\")\n",
        "\n",
        "# setup llm\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
        "\n",
        "# format retrieved info\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "# define the chain\n",
        "rag_chain = (\n",
        "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")"
      ],
      "metadata": {
        "id": "jT60ya1Pe0gS"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# answer the question\n",
        "user_questions = [\n",
        "    \"What are the advantages of using LangChain Expression Language?\",\n",
        "    \"What are the disadvantages of using LangChain Expression Language?\",\n",
        "    \"Why should I use LCEL?\",\n",
        "    \"What does Async mean?\",\n",
        "    \"How LCEL supports Async?\"\n",
        "]\n",
        "\n",
        "rag_chain.invoke(user_questions[-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "p1rPmoRDh1h_",
        "outputId": "0bcee531-4071-4a25-ae1b-f189ffa811ba"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'LCEL supports async by allowing chains to be called with both synchronous and asynchronous APIs. This enables the use of the same code for prototypes and production, with the ability to handle concurrent requests. LCEL also optimizes parallel execution for chains with steps that can be executed in parallel, reducing latency.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YOk4STuSiBuc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}